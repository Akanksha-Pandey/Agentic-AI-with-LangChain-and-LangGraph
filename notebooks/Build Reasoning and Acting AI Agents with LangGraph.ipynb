{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ReAct: Build Reasoning and Acting AI Agents with LangGraph**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **90** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're a software engineer on a mission: build an AI agent that doesn't just respond—it thinks. In this lab, you'll step into the role of an AI architect, designing a smart assistant that solves tough problems by reasoning through them and taking purposeful actions.\n",
    "\n",
    "Using the ReAct (Reasoning + Acting) framework, you'll teach your agent to think step by step, consult tools like search engines or calculators, and adapt on the fly. It’s not just about answers—it’s about how the agent gets there.\n",
    "\n",
    "By the end of the lab, your AI will face a mystery that can’t be solved with knowledge alone. It will need logic, resourcefulness, and the ability to act—just like you, the engineer who built it.\n",
    "\n",
    "## What is ReAct?\n",
    "\n",
    "**ReAct** stands for **Reasoning + Acting**. It's a framework that combines:\n",
    "\n",
    "1. **Reasoning**: The agent thinks through problems step by step, maintaining an internal dialogue about what it needs to do.\n",
    "2. **Acting**: The agent can use external tools (search engines, calculators, APIs) to gather information or perform actions.\n",
    "3. **Observing**: The agent processes the results from its actions and incorporates them into its reasoning.\n",
    "\n",
    "This creates a powerful loop: **Think → Act → Observe → Think → Act → ...**\n",
    "\n",
    "### Why ReAct Matters\n",
    "\n",
    "Traditional language models are limited by their training data cutoff and can't access real-time information. ReAct agents overcome this by:\n",
    "- Accessing current information through web searches\n",
    "- Performing calculations with specialized tools\n",
    "- Breaking down complex problems into manageable steps\n",
    "- Adapting their approach based on intermediate results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup-&-Installation\">Setup & Installation</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
    "            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Understanding-Tools-in-ReAct\">Understanding Tools in ReAct</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#1.-Web-Search-Tool\">1. Web Search Tool</a></li>\n",
    "            <li><a href=\"#Theory-behind-Web-Search-Tools\">Theory behind Web Search Tools</a></li>\n",
    "            <li><a href=\"#Testing-the-Search-Tool\">Testing the Search Tool</a></li>\n",
    "            <li><a href=\"#2.-Clothing-Recommendation-Tool\">2. Clothing Recommendation Tool</a></li>\n",
    "            <li><a href=\"#Why-this-Tool-Matters\">Why this Tool Matters</a></li>\n",
    "            <li><a href=\"#Creating-the-tool-Registry\">Creating the tool Registry</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Setting-up-the-Language-Model\">Setting up the Language Model</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Initializing-the-AI-Model\">Initializing the AI Model</a></li>\n",
    "            <li><a href=\"#Creating-the-System-Prompt\">Creating the System Prompt</a></li>\n",
    "            <li><a href=\"#The-System-Prompt's-Role\">The System Prompt's Role</a></li>\n",
    "            <li><a href=\"#Binding-Tools-to-the-Model\">Binding Tools to the Model</a></li>\n",
    "            <li>\n",
    "                <a href=\"#Understanding-Agent-State\">Understanding Agent State</a>\n",
    "                <ol>\n",
    "                    <li><a href=\"#What-is-Agent-State?\">What is Agent State?</a></li>\n",
    "                    <li><a href=\"#Demonstrating-State-Management\">Demonstrating State Management</a></li>\n",
    "                </ol>\n",
    "            </li>\n",
    "            <li>\n",
    "                <a href=\"#Manual-ReAct-Execution-(Understanding-the-Flow)\">Manual ReAct Execution (Understanding the Flow)</a>\n",
    "                <ol>\n",
    "                    <li><a href=\"#Step-1:-Initial-Query-Processing\">Step 1: Initial Query Processing</a></li>\n",
    "                    <li><a href=\"#Step-2:-Tool-Execution\">Step 2: Tool Execution</a></li>\n",
    "                    <li><a href=\"#Step-3:-Processing-Results-and-Next-Action\">Step 3: Processing Results and Next Action</a></li>\n",
    "                    <li><a href=\"#Step-4:-Final-Response-Generation\">Step 4: Final Response Generation</a></li>\n",
    "                </ol>\n",
    "            </li>\n",
    "            <li>\n",
    "                <a href=\"#Automating-ReAct-with-Graphs\">Automating ReAct with Graphs</a>\n",
    "                <ol>\n",
    "                    <li><a href=\"#Why-Use-Graphs?\">Why Use Graphs?</a></li>\n",
    "                    <li><a href=\"#Building-the-Core-Functions\">Building the Core Functions</a></li>\n",
    "                    <li><a href=\"#Constructing-the-State-Graph\">Constructing the State Graph</a></li>\n",
    "                    <li><a href=\"#Visualizing-the-Graph\">Visualizing the Graph</a></li>\n",
    "                </ol>\n",
    "            </li>\n",
    "            <li>\n",
    "                <a href=\"#Running-the-Complete-ReAct-Agent\">Running the Complete ReAct Agent</a>\n",
    "                <ol>\n",
    "                    <li><a href=\"#Final-Execution\">Final Execution</a></li>\n",
    "                    <li><a href=\"#The-Complete-ReAct-Cycle\">The Complete ReAct Cycle</a></li>\n",
    "                </ol>\n",
    "            </li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Key-Takeaways\">Key Takeaways</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#What-Makes-ReAct-Powerful\">What Makes ReAct Powerful</a></li>\n",
    "            <li><a href=\"#Best-Practices\">Best Practices</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Exercises\">Exercises</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Exercise-1---Build-a-Calculator-Tool\">Exercise 1 - Build a Calculator Tool</a></li>\n",
    "            <li><a href=\"#Exercise-2---Create-a-News-Summary-Tool\">Exercise 2 - Create a News Summary Tool</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Testing-Your-Solutions\">Testing Your Solutions</a></li>\n",
    "    <li><a href=\"#Authors\">Authors</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    " - Use the ReAct framework to solve multi-step problems with external tools\n",
    " - Teach an AI agent to reason step by step, take actions, and adapt based on results\n",
    " - Build a smart assistant that can handle tasks requiring logic and tool use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Installation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "\n",
    "- [`LangGraph`](https://www.langchain.com/langgraph): A framework for building stateful, multi-step AI applications using graphs.\n",
    "- [`LangChain`](https://www.langchain.com/): A toolkit that provides tools and abstractions for working with language models.\n",
    "- [`LangChain-OpenAI`](https://python.langchain.com/docs/integrations/llms/openai/): OpenAI integration for LangChain.\n",
    "- [`LangChain-Community`](https://python.langchain.com/api_reference/community/index.html): Community-contributed tools and integrations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (1.0.6)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph) (1.2.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph) (0.3.3)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph) (2.12.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
      "Requirement already satisfied: anyio in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.12.1)\n",
      "Requirement already satisfied: certifi in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (0.6.3)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core>=0.1->langgraph) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.6.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langgraph # \"langchain-openai>=0.3,<0.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langgraph==0.3.34 langchain-openai==0.3.14 langchainhub==0.1.21 langchain==0.3.24 pygraphviz==1.14 langchain-community==0.3.23\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Tools in ReAct\n",
    "\n",
    "Tools are the \"acting\" part of ReAct. They give the agent capabilities beyond just generating text. Let's build two essential tools:\n",
    "\n",
    "#### 1. Web Search Tool\n",
    "### Tavily Search API Key Setup\n",
    "\n",
    "We'll use Tavily search as our external research tool. You can get an API key at https://app.tavily.com/sign-in   \n",
    "\n",
    "\n",
    "**Disclaimer:** Signing up for Tavily provides you with free credits, more than enough for this project's needs. If you require additional credits for further use, please add them at your own discretion.\n",
    "\n",
    "![image.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/UjJx1-0vss4_3lwsUF8n0w/image.png)\n",
    "\n",
    "You need to copy the key from Tavily's API website and paste the key on the line ```os.environ[\"TAVILY_API_KEY\"] = \"YOUR_KEY_HERE\"```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-tavily in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (0.2.16)\n",
      "Requirement already satisfied: langchain_community in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (0.4.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-tavily) (3.13.3)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.20 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-tavily) (1.2.4)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.15 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-tavily) (1.2.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-tavily) (2.32.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.22.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain<2.0.0,>=0.3.20->langchain-tavily) (1.0.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain<2.0.0,>=0.3.20->langchain-tavily) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (0.6.3)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.15->langchain-tavily) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.15->langchain-tavily) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.15->langchain-tavily) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.15->langchain-tavily) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (4.12.1)\n",
      "Requirement already satisfied: certifi in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain<2.0.0,>=0.3.20->langchain-tavily) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.20->langchain-tavily) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.20->langchain-tavily) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.20->langchain-tavily) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.6.3)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain_community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain_community) (2.0.45)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain_community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain_community) (2.4.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-tavily langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vb/n3_mvf4s4j1ch65jb291mwf80000gn/T/ipykernel_97870/1142396889.py:13: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  search = TavilySearchResults()\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools import tool\n",
    "import os\n",
    "import json\n",
    "\n",
    "api_keys = json.load(open(\"../api_keys.json\"))\n",
    "os.environ[\"TAVILY_API_KEY\"] = api_keys[\"TAVILY_API_KEY\"]\n",
    "\n",
    "# Initialize the Tavily search tool\n",
    "search = TavilySearchResults()\n",
    "\n",
    "@tool\n",
    "def search_tool(query: str):\n",
    "    \"\"\"\n",
    "    Search the web for information using Tavily API.\n",
    "\n",
    "    :param query: The search query string\n",
    "    :return: Search results related to the query\n",
    "    \"\"\"\n",
    "    return search.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory behind Web Search Tools:\n",
    "- Enable real-time information retrieval\n",
    "- Overcome the knowledge cutoff limitation of language models\n",
    "- Return structured data that the agent can process and reason about\n",
    "\n",
    "### Testing the Search Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Weather for Tokyo, Japan - Time and Date',\n",
       "  'url': 'https://www.timeanddate.com/weather/japan/tokyo',\n",
       "  'content': 'timeanddate.com\\nFlag for Japan\\n\\n# Weather in Tokyo, Japan\\n\\nCool.\\n\\nFeels Like: 48 °F  \\nForecast: 61 / 40 °F  \\nWind: 13 mph ↑ from Southwest\\n\\n|  |  |\\n --- |\\n| Location: | Tokyo |\\n| Current Time: | Jan 15, 2026 at 11:07:59 pm |\\n| Latest Report: | Jan 15, 2026 at 10:00 pm |\\n| Visibility: | N/A |\\n| Pressure: | 29.86 \"Hg |\\n| Humidity: | 41% |\\n| Dew Point: | 29 °F |\\n\\nLocation of Tokyo\\nLocation\\n\\n## Upcoming 5 hours\\n\\n|  |  |  |  |  |  |\\n ---  ---  --- |\\n| Now | 12:00 am | 1:00 am | 2:00 am | 3:00 am | 4:00 am |\\n|  |  |  |  |  |  |\\n| 52 °F | 47 °F | 46 °F | 46 °F | 45 °F | 44 °F |\\n\\nSee more hour-by-hour weather\\n\\n## Forecast for the next 48 hours [...] | Amount of Rain | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" |\\n| Amount of Snow | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" |\\n|  |  |  |  |  |  |  |  |\\n ---  ---  ---  --- |\\n| \\\\ Updated Thursday, January 15, 2026 4:42:44 pm Tokyo time - Weather by CustomWeather, © 2026 | | | | | | | | [...] |  | Thursday | Friday | | | | Saturday | |\\n ---  ---  ---  --- |\\n|  | Evening | Night | Morning | Afternoon | Evening | Night | Morning |\\n| Forecast |  |  |  |  |  |  |  |\\n| Temperature | 46 °F | 45 °F | 47 °F | 60 °F | 49 °F | 43 °F | 46 °F |\\n|  | Broken clouds. | Clear. | Sunny. | Sunny. | Clear. | Partly cloudy. | Sunny. |\\n| Feels Like | 41 °F | 41 °F | 44 °F | 59 °F | 46 °F | 38 °F | 41 °F |\\n| Wind Speed | 10 mph | 7 mph | 6 mph | 6 mph | 8 mph | 7 mph | 9 mph |\\n| Wind Direction | SW ↑ | NW ↑ | NNW ↑ | NNW ↑ | N ↑ | N ↑ | NNW ↑ |\\n| Humidity | 51% | 60% | 61% | 36% | 48% | 63% | 54% |\\n| Dew Point | 29 °F | 32 °F | 35 °F | 33 °F | 30 °F | 31 °F | 30 °F |\\n| Visibility | 8 mi | 7 mi | 7 mi | 8 mi | 6 mi | 6 mi | 8 mi |\\n| Probability of Precipitation | 0% | 0% | 0% | 0% | 0% | 0% | 0% |',\n",
       "  'score': 0.93885136},\n",
       " {'title': 'Weather for Tokyo Prefecture, Japan - Time and Date',\n",
       "  'url': 'https://www.timeanddate.com/weather/@1850144',\n",
       "  'content': 'timeanddate.com\\nFlag for Japan\\n\\n# Weather in Tokyo Prefecture, Japan\\n\\nCool.\\n\\nFeels Like: 48 °F  \\nForecast: 61 / 40 °F  \\nWind: 13 mph ↑ from Southwest\\n\\n|  |  |\\n --- |\\n| Location: | Tokyo |\\n| Current Time: | Jan 15, 2026 at 11:07:59 pm |\\n| Latest Report: | Jan 15, 2026 at 10:00 pm |\\n| Visibility: | N/A |\\n| Pressure: | 29.86 \"Hg |\\n| Humidity: | 41% |\\n| Dew Point: | 29 °F |\\n\\nLocation of Tokyo Prefecture\\nLocation\\n\\n## Upcoming 5 hours\\n\\n|  |  |  |  |  |  |\\n ---  ---  --- |\\n| Now | 12:00 am | 1:00 am | 2:00 am | 3:00 am | 4:00 am |\\n|  |  |  |  |  |  |\\n| 52 °F | 47 °F | 46 °F | 46 °F | 45 °F | 44 °F |\\n\\nSee more hour-by-hour weather\\n\\n## Forecast for the next 48 hours [...] | Amount of Rain | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" |\\n| Amount of Snow | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" | 0.00\" |\\n|  |  |  |  |  |  |  |  |\\n ---  ---  ---  --- |\\n| \\\\ Updated Thursday, January 15, 2026 4:42:44 pm Tokyo Prefecture time - Weather by CustomWeather, © 2026 | | | | | | | | [...] |  | Thursday | Friday | | | | Saturday | |\\n ---  ---  ---  --- |\\n|  | Evening | Night | Morning | Afternoon | Evening | Night | Morning |\\n| Forecast |  |  |  |  |  |  |  |\\n| Temperature | 46 °F | 45 °F | 47 °F | 60 °F | 49 °F | 43 °F | 46 °F |\\n|  | Broken clouds. | Clear. | Sunny. | Sunny. | Clear. | Partly cloudy. | Sunny. |\\n| Feels Like | 41 °F | 41 °F | 44 °F | 59 °F | 46 °F | 38 °F | 41 °F |\\n| Wind Speed | 10 mph | 7 mph | 6 mph | 6 mph | 8 mph | 7 mph | 9 mph |\\n| Wind Direction | SW ↑ | NW ↑ | NNW ↑ | NNW ↑ | N ↑ | N ↑ | NNW ↑ |\\n| Humidity | 51% | 60% | 61% | 36% | 48% | 63% | 54% |\\n| Dew Point | 29 °F | 32 °F | 35 °F | 33 °F | 30 °F | 31 °F | 30 °F |\\n| Visibility | 8 mi | 7 mi | 7 mi | 8 mi | 6 mi | 6 mi | 8 mi |\\n| Probability of Precipitation | 0% | 0% | 0% | 0% | 0% | 0% | 0% |',\n",
       "  'score': 0.9345448},\n",
       " {'title': 'Tokyo January 2026 Historical Weather Data (Japan)',\n",
       "  'url': 'https://weatherspark.com/h/m/143809/2026/1/Historical-Weather-in-January-2026-in-Tokyo-Japan',\n",
       "  'content': '# January 2026 Weather History in Tokyo Japan\\n\\nThe data for this report comes from the Tokyo International Airport. See all nearby weather stations\\n\\n## Latest Report — 10:30 PM\\n\\nThu, Jan 15, 2026    38 min ago    UTC 13:30\\n\\nCall Sign RJTT\\n\\nTemp.\\n\\n54°F\\n\\n|  |  |\\n --- |\\n| Dew Pt. | 34°F  dry |\\n| Rel. Humidity | 47% |\\n\\nPrecipitation\\n\\nNo Report\\n\\nWind\\n\\n20.7 mph\\n\\n|  |  |\\n --- |\\n| Wind Dir. | 230 deg, SW |\\n\\nCloud Cover\\n\\nCeiling and Visibility OK\\n\\n|  |  |\\n --- |\\n| Vis. | 6.21 mi or greater |\\n| Alt. | 29.83 inHg |\\n\\nRaw: RJTT 151330Z 23018KT CAVOK 12/01 Q1010 TEMPO 22022G32KT RMK A2983 [...] | Today  Yesterday  Jan  2026  ---   194019501960197019801990200020102020   ---   2017201820192020202120222023202420252026   ---   SpringSummerFallWinter  JanFebMarAprMayJunJulAugSepOctNovDec   ---   12345678910111213141516171819202122232425262728293031 January 2026 Weather History in Tokyo Japan The data for this report comes from the Tokyo International Airport. See all nearby weather stations  Latest Report — 10:30 PM Thu, Jan 15, 2026    38 min ago    UTC 13:30  Call Sign RJTT  Temp.  54°F cold   |  |  |  --- | | Dew Pt. | 34°F  dry | | Rel. Humidity | 47% |  Precipitation  No Report  Wind  20.7 mph fresh breeze   |  |  |  --- | | Wind Dir. | 230 deg, SW |  Cloud Cover  Ceiling and Visibility OK   |  |  |  --- | | Vis. | 6.21 mi or greater | | Alt. | 29.83 inHg |  Raw: RJTT 151330Z [...] | 230,803 mi | | 27 |  | 64%  | 12:53 AM | WNW | 11:07 AM | ENE | 6:32 PM | S | 229,229 mi | | 28 |  | 75%  | 2:06 AM | WNW | 11:51 AM | ENE | 7:32 PM | S | 228,040 mi | | 29 |  | 85%  | 3:19 AM | NW | 12:45 PM | NE | 8:36 PM | S | 227,405 mi | | 30 |  | 92%  | 4:27 AM | NW | 1:50 PM | NE | 9:40 PM | S | 227,482 mi | | 31 |  | 98%  | 5:26 AM | NW | 3:02 PM | ENE | 10:42 PM | S | 228,375 mi |  Humidity Comfort Levels in January 2026 in Tokyo Winter 2026  Link  Download  Compare  Averages  History:JanFMAMJJASOND2025202420232022  Humidity Comfort Levels in January 2026 in Tokyo1815222911223344556677889910101111121213131414151512 AM12 AM3 AM3 AM6 AM6 AM9 AM9 AM12 PM12 PM3 PM3 PM6 PM6 PM9 PM9 PM12 AM12 AMDecFebNowNow  dry   55°F comfortable   60°F humid   65°F muggy   70°F oppressive   75°F',\n",
       "  'score': 0.93206495},\n",
       " {'title': 'Tokyo, Japan Weather Conditions | Weather Underground',\n",
       "  'url': 'https://www.wunderground.com/weather/jp/tokyo',\n",
       "  'content': \"# Tokyo, Tokyo Prefecture, Japan Weather Conditionsstar\\\\_ratehome\\n\\nicon\\n\\nThank you for reporting this station. We will review the data in question.\\n\\nYou are about to report this weather station for bad data. Please select the information that is incorrect.\\n\\nSee more\\n\\n(Reset Map)\\n\\nNo PWS\\n\\nReset Map, or Add PWS.\\n\\naccess\\\\_time 11:03 PM JST on January 15, 2026 (GMT +9) | Updated 52 seconds ago\\n\\nicon\\n\\nClear\\n\\nGusts 1 °mph\\n\\nTomorrow's temperature is forecast to be MUCH WARMER than today.\\n\\nicon\\nicon\\nicon\\nicon\\nicon\\nicon\\nicon\\nicon\\nAccess Logo\\n\\nWe recognize our responsibility to use data and technology for good. We may use or share your data with our data vendors. Take control of your data.\\n\\nThe Weather Company Logo\\nThe Weather Channel Logo\\nWeather Underground Logo\\nStorm Radar Logo [...] © The Weather Company, LLC 2026\",\n",
       "  'score': 0.84707206},\n",
       " {'title': 'Tokyo, Tokyo, Japan Monthly Weather | AccuWeather',\n",
       "  'url': 'https://www.accuweather.com/en/jp/tokyo/226396/january-weather/226396',\n",
       "  'content': \"# Tokyo, Tokyo\\n\\nTokyo\\n\\nTokyo\\n\\n## Around the Globe\\n\\nAround the Globe\\n\\n### Hurricane Tracker\\n\\n### Severe Weather\\n\\n### Radar & Maps\\n\\n### News & Features\\n\\n### Astronomy\\n\\n### Business\\n\\n### Climate\\n\\n### Health\\n\\n### Recreation\\n\\n### Sports\\n\\n### Travel\\n\\n### Warnings\\n\\n### Data Suite\\n\\n### Forensics\\n\\n### Advertising\\n\\n### Superior Accuracy™\\n\\n### Video\\n\\n## Monthly\\n\\n## January\\n\\n## 2026\\n\\n## Daily\\n\\n## Temperature Graph\\n\\n## Further Ahead\\n\\nFurther Ahead\\n\\n### February 2026\\n\\n### March 2026\\n\\n### April 2026\\n\\n## Around the Globe\\n\\nAround the Globe\\n\\n### Hurricane Tracker\\n\\n### Severe Weather\\n\\n### Radar & Maps\\n\\n### News\\n\\n### Video\\n\\nTop Stories\\n\\nWinter Weather\\n\\nSnow, lake-effect and freeze-ups to accompany colder air into next wee...\\n\\n1 hour ago\\n\\nWeather Forecasts [...] 1 hour ago\\n\\nWeather Forecasts\\n\\nFlorida to have freezing weather as temperatures tumble in Southeast\\n\\n10 minutes ago\\n\\nAstronomy\\n\\nCrew-11 astronauts splash down off California after medical evacuation\\n\\n28 minutes ago\\n\\nWinter Weather\\n\\nWeekend storm to bring snow to part of U.S. East Coast\\n\\n1 hour ago\\n\\nAstronomy\\n\\nMarch’s total lunar eclipse will turn the moon red, here’s when to see...\\n\\n20 hours ago\\n\\nFeatured Stories\\n\\nAstronomy\\n\\nNASA to roll out Artemis II rocket ahead of astronaut moon launch\\n\\n23 hours ago\\n\\nWeather News\\n\\nKilauea’s latest eruption sent lava 800 feet high\\n\\n1 day ago\\n\\nHow to shoot the northern lights on your phone\\n\\nLightning over Milan, like you've never seen it\\n\\nLATEST ENTRY\\n\\nISS astronaut captures surreal photo of lightning and Milan at night\\n\\n2 days ago\\n\\nWinter Weather [...] 2 days ago\\n\\nWinter Weather\\n\\nAvalanches in Washington, Wyoming turn deadly\\n\\n21 hours ago\\n\\n## Weather Near Tokyo:\\n\\n...\\n\\n...\\n\\n...\",\n",
       "  'score': 0.5414337}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tool.invoke(\"What's the weather like in Tokyo today?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test demonstrates how the agent can access current information that wasn't available during training.\n",
    "\n",
    "#### 2. Clothing Recommendation Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def recommend_clothing(weather: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns a clothing recommendation based on the provided weather description.\n",
    "\n",
    "    This function examines the input string for specific keywords or temperature indicators \n",
    "    (e.g., \"snow\", \"freezing\", \"rain\", \"85°F\") to suggest appropriate attire. It handles \n",
    "    common weather conditions like snow, rain, heat, and cold by providing simple and practical \n",
    "    clothing advice.\n",
    "\n",
    "    :param weather: A brief description of the weather (e.g., \"Overcast, 64.9°F\")\n",
    "    :return: A string with clothing recommendations suitable for the weather\n",
    "    \"\"\"\n",
    "    weather = weather.lower()\n",
    "    if \"snow\" in weather or \"freezing\" in weather:\n",
    "        return \"Wear a heavy coat, gloves, and boots.\"\n",
    "    elif \"rain\" in weather or \"wet\" in weather:\n",
    "        return \"Bring a raincoat and waterproof shoes.\"\n",
    "    elif \"hot\" in weather or \"85\" in weather:\n",
    "        return \"T-shirt, shorts, and sunscreen recommended.\"\n",
    "    elif \"cold\" in weather or \"50\" in weather:\n",
    "        return \"Wear a warm jacket or sweater.\"\n",
    "    else:\n",
    "        return \"A light jacket should be fine.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why this Tool Matters:**\n",
    "- Demonstrates domain-specific reasoning\n",
    "- Shows how tools can process and interpret data from other tools\n",
    "- Illustrates the composability of ReAct systems\n",
    "\n",
    "#### Creating the Tool Registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[search_tool,recommend_clothing]\n",
    "\n",
    "tools_by_name={ tool.name:tool for tool in tools}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This registry allows the agent to dynamically select and invoke the appropriate tool based on the task at hand.\n",
    "\n",
    "## Setting Up the Language Model\n",
    "\n",
    "### Initializing the AI Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.6 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-openai) (1.2.7)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-openai) (2.15.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.6.3)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (4.12.1)\n",
      "Requirement already satisfied: certifi in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.6->langchain-openai) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/akanksha/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.6->langchain-openai) (2.6.3)\n",
      "Using cached langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: langchain-openai\n",
      "Successfully installed langchain-openai-1.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", model_provider=\"openai\", api_key= api_keys[\"OPENAI\"][\"API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using GPT-4o-mini as our reasoning engine. This model will:\n",
    "- Analyze user queries\n",
    "- Decide which tools to use\n",
    "- Process tool results\n",
    "- Generate final responses\n",
    "\n",
    "### Creating the System Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage,SystemMessage\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "You are a helpful AI assistant that thinks step-by-step and uses tools when needed.\n",
    "\n",
    "When responding to queries:\n",
    "1. First, think about what information you need\n",
    "2. Use available tools if you need current data or specific capabilities  \n",
    "3. Provide clear, helpful responses based on your reasoning and any tool results\n",
    "\n",
    "Always explain your thinking process to help users understand your approach.\n",
    "\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"scratch_pad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The System Prompt's Role:**\n",
    "- Defines the agent's behavior and personality\n",
    "- Establishes the reasoning pattern (think → act → observe)\n",
    "- Encourages transparency in the decision-making process\n",
    "\n",
    "### Binding Tools to the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_react=chat_prompt|model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a model that can:\n",
    "- Understand when to use tools\n",
    "- Generate properly formatted tool calls\n",
    "- Process tool results in context\n",
    "\n",
    "## Understanding Agent State\n",
    "\n",
    "### What is Agent State?\n",
    "\n",
    "In ReAct, state management is crucial, as the agent must maintain context across multiple reasoning and acting steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (Annotated,Sequence,TypedDict)\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of the agent.\"\"\"\n",
    "\n",
    "    # add_messages is a reducer\n",
    "    # See https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts:**\n",
    "- **State**: Contains the conversation history and context.\n",
    "- **Reducer**: `add_messages` automatically handles adding new messages to the conversation.\n",
    "- **Type Safety**: TypedDict ensures our state structure is well-defined.\n",
    "\n",
    "### Demonstrating State Management\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After greeting: [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='c183266b-488f-4311-a160-d9525f6423bd')]\n",
      "After question: {'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='c183266b-488f-4311-a160-d9525f6423bd'), HumanMessage(content='Weather in NYC?', additional_kwargs={}, response_metadata={}, id='dea93930-8fc6-4ea9-a6f8-11375d032a37')]}\n"
     ]
    }
   ],
   "source": [
    "# Example conversation flow:\n",
    "state: AgentState = {\"messages\": []}\n",
    "\n",
    "# append a message using the reducer properly\n",
    "state[\"messages\"] = add_messages(state[\"messages\"], [HumanMessage(content=\"Hi\")])\n",
    "print(\"After greeting:\", state[\"messages\"])\n",
    "\n",
    "# add another message (e.g. a question)\n",
    "state[\"messages\"] = add_messages(state[\"messages\"], [HumanMessage(content=\"Weather in NYC?\")])\n",
    "print(\"After question:\", state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstrates how the state accumulates context over the conversation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual ReAct Execution (Understanding the Flow)\n",
    "\n",
    "Before building the automated graph, let's manually step through a ReAct cycle to understand what happens:\n",
    "\n",
    "### Step 1: Initial Query Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'model_provider'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m dummy_state: AgentState = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage( \u001b[33m\"\u001b[39m\u001b[33mWhat\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms the weather like in Zurich, and what should I wear based on the temperature?\u001b[39m\u001b[33m\"\u001b[39m)]}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mmodel_react\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscratch_pad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdummy_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m dummy_state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]=add_messages(dummy_state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m],[response])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3151\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3149\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3150\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3151\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3152\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3153\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5557\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5550\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5552\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5555\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5556\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5558\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5559\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5560\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1386\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1384\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1385\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1389\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1390\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1391\u001b[39m ):\n\u001b[32m   1392\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1381\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1374\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1375\u001b[39m             response,\n\u001b[32m   1376\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1377\u001b[39m             metadata=generation_info,\n\u001b[32m   1378\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1379\u001b[39m         )\n\u001b[32m   1380\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1382\u001b[39m         response = raw_response.parse()\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Completions.create() got an unexpected keyword argument 'model_provider'"
     ]
    }
   ],
   "source": [
    "dummy_state: AgentState = {\n",
    "    \"messages\": [HumanMessage( \"What's the weather like in Zurich, and what should I wear based on the temperature?\")]}\n",
    "\n",
    "response = model_react.invoke({\"scratch_pad\":dummy_state[\"messages\"]})\n",
    "\n",
    "dummy_state[\"messages\"]=add_messages(dummy_state[\"messages\"],[response])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happens Here:**\n",
    "1. The user asks a complex question requiring current data.\n",
    "2. The model analyzes the query and realizes it needs to search for weather information.\n",
    "3. The model generates a tool call for the search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Tool Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tool_call = \u001b[43mresponse\u001b[49m.tool_calls[-\u001b[32m1\u001b[39m]\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTool call:\u001b[39m\u001b[33m\"\u001b[39m, tool_call)\n\u001b[32m      4\u001b[39m tool_result = tools_by_name[tool_call[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]].invoke(tool_call[\u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "tool_call = response.tool_calls[-1]\n",
    "print(\"Tool call:\", tool_call)\n",
    "\n",
    "tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "print(\"Tool result preview:\", tool_result[0]['title'])\n",
    "\n",
    "tool_message = ToolMessage(\n",
    "    content=json.dumps(tool_result),\n",
    "    name=tool_call[\"name\"],\n",
    "    tool_call_id=tool_call[\"id\"]\n",
    ")\n",
    "dummy_state[\"messages\"] = add_messages(dummy_state[\"messages\"], [tool_message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happens Here:**\n",
    "1. Extract the tool call from the model's response.\n",
    "2. Execute the tool using the specified arguments.\n",
    "3. Create a ToolMessage containing the results.\n",
    "4. Add the tool result to the conversation state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Processing Results and Next Action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model_react.invoke({\"scratch_pad\": dummy_state[\"messages\"]})\n",
    "dummy_state['messages'] = add_messages(dummy_state['messages'], [response])\n",
    "\n",
    "# check if the model wants to use another tool\n",
    "if response.tool_calls:\n",
    "    tool_call = response.tool_calls[0]\n",
    "    tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "    tool_message = ToolMessage(\n",
    "        content=json.dumps(tool_result),\n",
    "        name=tool_call[\"name\"],\n",
    "        tool_call_id=tool_call[\"id\"]\n",
    "    )\n",
    "    dummy_state['messages'] = add_messages(dummy_state['messages'], [tool_message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happens Here:**\n",
    "1. The model processes the search results.\n",
    "2. It realizes it needs to use the clothing recommendation tool.\n",
    "3. It extracts weather information and calls the clothing tool.\n",
    "4. It receives clothing recommendations based on the weather data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Final Response Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final response generated: True\n",
      "More tools needed: True\n"
     ]
    }
   ],
   "source": [
    "response = model_react.invoke({\"scratch_pad\": dummy_state[\"messages\"]})\n",
    "print(\"Final response generated:\", response.content is not None)\n",
    "print(\"More tools needed:\", bool(response.tool_calls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happens Here:**\n",
    "1. The model has all necessary information.\n",
    "2. It synthesizes weather data and clothing recommendations.\n",
    "3. It generates a comprehensive response to the user.\n",
    "4. No more tool calls needed—the reasoning cycle is complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating ReAct with Graphs\n",
    "\n",
    "### Why Use Graphs?\n",
    "\n",
    "Manual ReAct execution is educational but impractical for real applications. LangGraph automates this process with a state machine that handles the reasoning loop automatically.\n",
    "\n",
    "### Building the Core Functions\n",
    "\n",
    "#### Tool Execution Node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_node(state: AgentState):\n",
    "    \"\"\"Execute all tool calls from the last message in the state.\"\"\"\n",
    "    outputs = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "        outputs.append(\n",
    "            ToolMessage(\n",
    "                content=json.dumps(tool_result),\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\"messages\": outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Purpose:**\n",
    "- Automatically execute all tool calls from the model\n",
    "- Handle multiple simultaneous tool calls\n",
    "- Return properly formatted tool messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Invocation Node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: AgentState):\n",
    "    \"\"\"Invoke the model with the current conversation state.\"\"\"\n",
    "    response = model_react.invoke({\"scratch_pad\": state[\"messages\"]})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Purpose:**\n",
    "- Call the ReAct-enabled model\n",
    "- Pass the full conversation context\n",
    "- Return the model's response (which may include tool calls)\n",
    "\n",
    "#### Decision Logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Determine whether to continue with tool use or end the conversation.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Purpose:**\n",
    "- Implement the control flow logic\n",
    "- Decide whether the agent needs to use more tools\n",
    "- Route the conversation to either tool execution or completion\n",
    "\n",
    "### Constructing the State Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Add edges between nodes\n",
    "workflow.add_edge(\"tools\", \"agent\")  # After tools, always go back to agent\n",
    "\n",
    "# Add conditional logic\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",  # If tools needed, go to tools node\n",
    "        \"end\": END,          # If done, end the conversation\n",
    "    },\n",
    ")\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph Structure Explained:**\n",
    "1. **Agent Node**: Where reasoning happens and tool calls are generated.\n",
    "2. **Tools Node**: Where tool execution occurs.\n",
    "3. **Conditional Edge**: Determines whether to continue or finish.\n",
    "4. **Entry Point**: Conversation always starts with the agent reasoning.\n",
    "### Visualizing the Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANkAAAERCAIAAAB5EJVMAAAQAElEQVR4nOydB1wUxxfHZ/cKXZo0KYKiYgN7iz0G87fFklhjQ4PGErsxatSoiSVqNPYWa4xiI8YWY2KMkoiCoCKoqIB0lN6Oq/93t3IeByh3t3vswnw/eO5tu7vd375582bmDV+hUCAMhgXwEQbDDrAWMWwBaxHDFrAWMWwBaxHDFrAWMWwBa5FZSopR5N856S+KRYVyqUQmESkIHlLIECKUWyGeRvLgP+VbWEmQrxcQqdyuCrdR+6n+hz+5ch/4k0tVZ1dtRIrSZXV0jqDOSL2REySpkL/eAut4AoVcQqi/IaH6AuodAIEpQfJJMzNeXVcTv/esLevykFEgcHyRIU5tTc5MKZGK5QITUmjKE5qQBKmQiOQkn5BLFaAn5YVXgLCUt0D5KlOotEgtvNbK67sDuxFKfSHVnqAeuaT0rhGlSkUaWoTD4UDqrVLWhEL+5i7zBKRM8kZ6JE/5BTS1KDTjySQKiVghKpRJJXJ4WmwchB9NdbOwJhGTYC3Sz7F1iZlpJRZ1+D5trbsMskUcJ/RiVtSt3KJ8qZWNYMJyT8QYWIt08s+ZV/dv5ti7mIxa4I5qHCc2JmYkiRq3suo73hkxANYibZzYkJSTKf74C3d7FwGqochkaP/XcaZmvHFfeyC6wVqkhytHMqCCMnZJfVQLOLEhhS+QD5vlhmgFa5EGjnybABWFsUtrhRApjm9ILi6QTlxB509mtmZUGzizLQVqt7VKiMDI+a5mFuTxDYmIPrAWDeJJeFH6C9G4pfQ7T+xn5AL3nJeSWxezEE1gLRrEn0FprXtyPmqjNx+Mdon4OxvRBNai/vx1/CWfT3bqV3u12NDPTGhKnt2RgugAa1F/nkTkN+9sjWo3XQY4pMUXIzrAWtST2LvQwKzoMsCoRjEoKGj58uVIdxYtWvTrr78iBmjawRJaEW9doKGkxlrUE/CTLG2NHdOOjo5GeqH3gVXBztnk6b0CZDA4vqgne5bENWxh+f4oB8QA8fHxu3btCg8Ph7vj6+s7bty4Vq1aBQYG3r17l9rh6NGjPj4+J06cuHHjRlRUlImJSZs2baZPn+7mpow/L1y4kMfjubi4HD58eP369fCWOsrS0vLvv/9GdBPxV07olaypaxsgw8B2UU+kJfKGfpaIAcRiMcgOxLR169adO3fy+fw5c+aIRKI9e/a0aNGif//+YWFhIMTIyMjvv//ez89vw4YN33zzTVZW1tKlS6kzCASCpyo2bdrUunXrkJAQWPn1118zIUSgRWcbuUbHH73B/Rf1BCyWZzMzxAAJCQkgrFGjRoHg4O3atWvBHEqlUq3dWrZsCe6jh4cHiBXeSiQSkGxubq61tTVBECkpKUeOHDE1NYVNJSUliEkEZsqeb0mxYrdGQmQAWIv68OqFWN3FkHZAXra2titWrOjXr1/btm3B8rVr1678bmA4k5KSNm7cCGV0YWEhtRJEDFqEBS8vL0qIRoJQZGeIDNQiLqP1QWmjFExpEZy/vXv3du3a9dixY5MmTRo8ePDFixfL73b9+vW5c+c2a9YMdr5z5862bdu0ToKMCEGQhlc8sBb1wcFZKJfT4CFVhqen5+zZs8+fPw8On7e397Jlyx49eqS1z9mzZ6FCA/WVxo0bQ6Gcn5+Pqg+ZTGHrYGhUAWtRH3hCRJIoLU6MGAAq0efOnYMFKGS7d+++bt068AhjYmK0dgPX0NHRUf32r7/+QtUHGEX3JubIMLAW9QQCvNDughgARLZy5crNmzcnJiZCPebAgQNQcQGvETa5u7uDdwglMviFYA5v3boFdWrY+vPPP1PHpqamlj8hlNegWvXOiG6ibubR4jxjLepJHTtB4pNCxAAgu8WLF1+6dGnIkCHDhg2LiIiAWGODBsro3dChQ6E4hnI5NjZ22rRpXbp0AZexc+fOaWlpENYB3/GLL764fPly+XMGBASAgufNm1dcTE97nSYxd/KEZjSMFcSxbj25dz33v4uvpq5riGo9uxc9b9zWqtcnhob9sV3UE78eytDJ/X/yUO0mNb5EXCIzXIgIxxcNwcnDNPRKpm/3OpXtAM0nT548Kb9eBtVOhYKKUZcnODjYxsYGMQA01UD1vMJN8JVIkgQHoMKtV69erezbXjmSau9MT/wIl9EGsW3uU//Rzo3bVdwY+PLlS2gOqXATtIVUFgKsV68eYgxoj0G6U9lXys2UHV79fOYPjRAdYLtoEK162P51Mr0yLTo4MNJzwhDoFfrxDQkNWtZBNIH9RYPo+pG9hTU/aBOdQ5C4wm+7UgRCsn+AE6IJrEVDGbu4fn629MK+dFSbuHEmKzleFPCNJ6IP7C/Sw9E1Lyws+EO+YNDVYw9/HHmZ8Lhw8mpPRCtYi7Tx04oEPk8x7mtPVKM5tu5FYb7ss9VeiG6wFunk1Oak9ERRo1Z1/Mc6ohrHtZMZMbfzbR0EoxYyMh4ca5FmkmLFlw4li0UyB1fT7oOdnL04n+cp96X0r5MZKc+KeEKy1xCnJh0sEDNgLTJC9K38/y5ligqlJCLM6/DMrQXmljwowcWSMlebJJFclWpWuVbVB025rO6MBgcrlDeI2q3sIRCVVpRbqVzWPByVnrbCHQhVxlCST8qlZfq/CUxgDSrIlRbmSYvypLCPmSXPt6tNe39mBz1iLTLLvb/z4qILoKItEcvlcoWkpMzVptSgfCVKtahao96qSkxLaK1UrlKlqlXmnlX9I3mkKp+yQpmCttzhmh+kWlXauKLKaaspdAqBUPmJfCFpZc1397Fo789II1B5sBa5zcGDBwsKCmbMmIG4D2534TZSqbSylmLOgbXIbWqSFnG7C7fBdhHDFiQSiUBQQ9KDYy1yG2wXMWwBaxHDFrAWMWwBtIj9RQwrwHYRwxawFjFsAWsRwxawFjFsAWLdWIsYVoDtIoYtYC1i2ALWIoYt4L4RGLaA7SKGLWAtYtgC1iKGLWAtYtgCrrtg2AK2ixi24OLiwuPRMIcAG8DjALlNRkaGWMzIlEfGB9tFbgMFNBPTB1ULWIvcBmsRwxawFjFsAWsRwxawFjFsAWsRwxawFjFsAWsRwxawFjFsAbQok8lQjQBrkdtgu4hhC1iLGLaAtYhhC1iLGLaAtYhhCzVJi3jeK07i7++fmZmpvncEQcjl8kaNGgUFBSHOgvt1c5I+ffqo5qx8DWjRzMxsxIgRiMtgLXKSMWPGuLm5aa6Bt0OHDkVcBmuRk7i6uvbs2VP9lsfjDRo0iCAIxGWwFrnK+PHj3d3dqWWQJteNIsJa5C729vZ9+/ZFqooLLJibmyOOg+vRjHPncnb2K2lJsURrPUEqp7gnBUj+ZotqdnH1m9fTliOtO8TjkzKpcvpxmUwWHh4OC61atxYKBHAqJNOemFy5P095l7XWUyfXnMgcdpPJ3nyUwJRnbSPoPNAOGQusRQa5GZz18N8cgg+3mRSLymmEmtaep5DLKvHzKBmWEyPJV8ilrw+hbh/lKcIHKWTllKuSHZxEofX5UCLKS1+p3eBwjUilwIRQyEGdcvcmFv0DnBDzYC0yRfifuWFXsz4c42rnLkScpSBL8dvehOadrN4bZI8YBmuRESL+zA+7+mrkIi9UIwjakNCwhUXPEXURk+C6CyNEXM/yaFYH1RR8OtnG3stHDIO1yAglImmzLjaopuDbtY5UohAXIEbBWmQEqVRhYoFqElKZPDeP2SRSWIvMAE54Dcn+VQrz1QrcZwzDFrAWMWwBaxHDFrAWMVUDWiMZdhmxFhmD5HYPLm2gFZHhH4S1yBhy3KClG1iLGLaAtYipGgTV4YdBsBaZgerrhdEFrEVmIFBNE6NC2VkSMQnWInPguotuYC0yBpaijuC+EbWOs8FBa9YtR+wD28Vax+PH0UgvmPZ/sRYZQ8dbd+bsiVu3bsTERAlNTPx820yaNN213uvMEOd+Ox0UdCQvP69Tp66TJk4bOXrA0iXfvt9bOSD18u+/wda4uKdeXt69e/kPGzqKGof1zcpFsNDn/f+tXb+iuLioWbOWUwNnNW3aYvbcwHv37sIOV65cOHniUt26DlX/hkw7HbiMZg4dxPjgQeTWbd83b+63cuWGRV9+k52d9e13S6lNMY8e/rB5TY8efY4cOtOze5+Vq7+ClSSpvHFX/7y8bv03jRv5HDt6bvKk6adOH9u2YyN1FJ/Pfxh9/4+rF3ftPHLpwk0ToQlVLm/etAcU6e/f/9qfYToJ0QhgLTKGLhEQsFsH9geNGT2xdat27dt1Gv7Jp2Agc/NykdKAnbezs584Yaq1tU2XLt1hq/qoixeDfX1bz561yNbWrk3r9hPHTw0ODgIdU1uLi4oWzF9Wz8UVdPl+7w8TExOKiooQi8FaZAU8Hi8lJemrxbMGDOrR6/12i5fOgZU5KlU9j3sKlgz0RO3Zvdv71IJcLo96eK99u87qk7Ru3R5W3n8QQb119/BUJ5OwtLSC1/z8PKQ3BOMOI/YXmUGhW4tZSMj1pcvmgV2cEjirYcNGYeGhC7+cQW0qKMh3dHRW7wnWkVoQi8USiWT/TzvgT/NUartIleM0gvuMcRMdTcj5i2dbtmwFPh/1FvSn3mRiYiqVvMlykpn1ilowNTUFs+f/Qf/u3d/XPFU9FzfEBArG6y5Yi8yhw73Ly8t1dnJRv71x4y/1squre2zsI/XbkJC/1csNGzbOL8gHF5N6C2YyNTXZ0dEY+UaYAPuLjKGLGfFu2PhO2K2IyDCpVHry1M/UyrT0VHh9r0uPhIS4Y78cVCgUsA/UuNVHfTZpBkjz4qVfwU2E9StXfTV3/lQou9/+WSBuqBjdjbjDtqoM1iIrCAiY1rFDl6Vfz/X/sHN6ehqEdXyaNFv01RcQtenerfeQwcMPHd4zZNgHZ4NPTJ6s9CMFAgG8QrG+Z9fP9+9HwKb5C6cVFhasXrXJxMTk7Z81sP9QCD0uWDg9KzsTsQmcT4cRts55OmKOl5k1DxkMWMr4+Ofe3o2ptxBunDZ9/N7dx9RrjMPBFU9HLfCoW4/BPFXYLjIGTeNdHkRFfjZl9JYf16WlpUZHP9iyZW3z5r5Q10ZGB9ddOAtN412gajJv7pJLl88FTB4OYcJ2bTtNnTqb66m5KwRrkQMM6D8E/lBNB2sRUzUIRODxLpwEIsM1zBWXv8mmzBBYi8xAMN5iZmyUY/XxeBeOgmNlOoK1iGELWIsYtoC1yBg1LLcT82AtMgbO7aQjWIsYtoC1iGELWIuMQPIRT0hDJx32wOcTApLZyeRwPx1GUI6lelqMagr5GWJoAbRxRoyCtcgI1va8+yGvUE3hv98zLa0ZL0KxFuknLS1t94Vx+ZmSiMvZiPskP5W+fFE8dokHYhjcr5tO7t+/37Rp09TUVA8P5Z3b/3W8iSnP3cfSysFELpVW5QyK0oZs1f+quaHLTSKtXiaIMsPzqPWK0qHMWveVkGt31yAqaaekzsAjUUGO7MWjwvwc8dS1DRDzYC3SxsmTJy9durR/UzMB0AAAEABJREFU/37NvlVntqVmpYlkYrlYUuY6U9Pal1lT+h+1Xr1DZVpU7Q+7EKjcekVZvVLnIUkkl5c9M/H6eAU1nLvsJ/L4SCDg2ToJPp7FzCDXcmAt0sDdu3fbtGkTFhbWrl07ZFwOHz6cm5s7c+ZMpC/nzp377rvv7OzsevXqNXTo0IYNG6JqAvuLBiGTyQICApKTk2HZ+EJEyuQklvb2Bs147+fn5+zsnJGR8csvv0yZMmXy5Mm///47qg6wXdQfqKNYWFjExcX5+voiLjNhwgTwdKmcJ/B0CYVCJyenHj16zJs3DxkRbBf1AfQHJRqfz7eysqpeIebk5EAZjQyjZcuW6mWIjIIck5KSwPdFxgVrUTcyM5Xj258+fQpuVt26dVF1c+zYsdOnTyPDaN++fZ06dTTXNGjQ4OrVq8i4YC3qwNGjR1etWgULH3zwAVhExAJsbGxsbW2RYbRo0QLqLtQyGEV4xk6dOoWMDtZilXj58iVSRlAUmzdvRmxi9OjRQ4YYOlwVhOjo6AgqlMvlERERUJUODQ1FRgdr8R3AHVqyZElsbCwsjx07FrGMrKysvDwDMnyWAsU0uL8QnILl7du3f//99/Hx8ci44Hr0O7hx40ZxcbG/vz9iJSAaaOMZMWIEoptu3bpduXLFzMwMGQtsFysGrMKnn36KVLeEtUJENPmLFXLhwoX+/fsjI4LtYsWAvQE/zNvbG9ViwDNZtmwZxMCRUcBaLMNvv/0G8Zo5c+YgjgAxJhMTE2h9Qcxw8+ZNqFMbp8aGy+jXSKVSaAcD551DQgR+/PHH69evI8bo2rUreClr1qxBzIO1qGTr1q3p6enW1tbLly9HnAJigUxHOocNGwZX5qeffkIMg8totGfPHijmxo8fjzCVA09px44d+/Xrhxij9moRPK3jx49Pnz5dJBKZmpoibgJBeHNzcwsLC8Q8U6ZMCQwMbNu2LWKG2ltGBwQE9OrVC6kmSkGcZf369bdv30ZGYffu3dAEmpSUhJih1o1JDQsLE4vFXbp0+fXXXxH3sbe31+rWwCjBwcGdO3f+559/qIkU6KV2ldHQ2AoPN0QoOG0LqxdodRw5ciQ0ySC6qS1l9Llz5+DV0dFx165dNUmIUP0HfxcZETs7uy1btjDRNF8rtAh1wISEBKSc8skV1SxWrFjx4MEDZFyaNm06adKk+fPnI1qp4VqEZgN4hQtnyOgkNgOWXj0xrzHp2bNn+/btoaUU0UeN9Rdzc3P79u0LEdpmzZohDDNAq4+Njc24ceMQHdRALULQAaqWBQUFYDPUU4DXVNLS0mxtbd85ByBzLFmypEePHrR0ZTKGFgsLC+VyhudjKOXOnTvwsJ48eZKJoINO5OfnI+a5cOECNIcwPfIGHum3dGScPHkyuEB+fn7IMIyhRYgCGEGLUqkULtmjR4+gOR9VN3BVqVFaTJOXlweNLjwes/n1SJJUD4ipkAEDBuzbt8/Z2aBMZDVEi3BLQIjgxcMlo8b5Vi9G06JxeKcWkWqUArQAGTI3Fufr0TKZDKna8aqlOlntwM9nicdveD9wDmsRbC1YXGpZKGQ2ZSprgXCB0XzxtwM1xXXr1k2cOBHpCye1CJYAmkT79esHC0y7SiwHfj40KTHalavqtGzZcsyYMYsWLUJ6wT0tlpSU5OTkUMu1Voigvw0bNsCCtbU1tIKMHj0asYM+ffqAIn/44QekO1zSIlUYgYfE0Mg3DkGN10aqq+Hj40MNWWQJYBqhvDp27BjSkeoJBUdHR//888+PHz+GxxrCY3ApqZoHPO6//PLL+vXrV69eDS3IXl5eQ4YMoeKoELs+evTo9evXIdAFDVBubkZKUEkjoaGh27dvf/XqVYMGDQYOHAjNQtT6//77D35aYmIihOgbNmw4ffp08L1g/bfffgvV0t69e2/cuLG4uBg0B5E8eF2wYAHVBn316lW4UHDg3r17L168CGtGjBgxduxYiCrACaE+17Zt26lTp1JJ8QYPHgwq+eSTT6gP3bRp0/Pnz7dt24ZU4bBDhw5BLTgjI6N58+aDBg3q0KEDMoC5c+d++eWXEOKBL1/1o6rBLiYnJy9evFgkEoElX7ZsWVxcHFxcqSqFMASoQXM7duyYPXv2pUuXunXrBvvABZJIJH/88cfly5enTZu2ZcsW+JEgZcQpQIgrV66cMGHCqlWr3nvvPfhd165dQ6o8orAGirYjR47AZYEfS+kDqSLMMTExf/75J0Tvg4ODoXGFKpehFRgUCYfABdEaNQuHnDp1CkIwQUFBINCHDx+CKN/53eCCnz17FiQIioRrDvq+ceMGMgyoxxw+fBi+QNUPqQYtwj2ASwYqdHd3r1+/Psju2bNn//77L7UVZAePL/hAlEkAa//06VPQKDz33VRYWVmBpWzVqhXiFHBjQILwi8BWjRo16uOPPy4qKlKvB/MPRQQ0nQcGBoJ9evLkCXUUmMM5c+a4uLjAFYPSAJo3qaPUQHOwVkivXr16I0eOpHKEwmepS/PKAP8b7Ovw4cMhIgOGGaw1fJAeJWx5Dh48OG/ePCgHqrh/NWgRCugmTZrApafeOjk5wbWOiopS7wBbqQWqagJNiKDIlJQUKiE7RaNGjRB3AE8XzL/6dyFVuxkVjdNa37hxY3gF74V6C4+rOm5KDYKGckPzzFR4VRPNKwPPrZZ2ywNiFYvFmqNYfH194VvRkqZHp6BjNfiLcDXhuf/www81V2Znv5l+Ah50KLLhVT2kCC4oXHTNJlFu9YcFhwTkWL4HAzxmYJY011O/US2gd7YhwcU0MNYN3wFey6eghTti+OgFsCbgAEChv3Tp0nfuXA1ahNYkcJC1Ohpp/Wy4eZrxGrAN8BZum3oNFF6IO4DaQFXUXddaj1Q/Vr2GUuE7G9zUgHbLm8aqoI6QUzWbWbNmQeGuuYODgwOig927d0P9qSp7VoMWoXYM/jhEodQPPVSZtXpcg3sEW6Wlc6KAjYSqJTjy6h2MNviNFuBBgsJX05E/cOAAlIxTpkyBIlXzd4EDg1SXqIpnhganKvaLgz01H2D1cD6QIPVIqDvagEUEW0tLmyo4APn5+W3atKnKztXgLw4dOhQeyl27doE9gCuyf/9+eG60sv1BEazVrNe9e/ebN29CcwssQyXx0aNHiFOA2xQeHg6V3Hv37p0/fx5+gqenJ6yH2ivU26CaDPcMNu3ZsweqZe/MKQUCgisQGRkJuqliGyBUveECUrYZAmfqKgVoDmJqEJcAlx0eD6hBQ3UeYk+IDk6cOFH1fHzVYBfBoQYhws2YOXMmxMbAc4eqtNbVp/xFzTVQ94S21507d3733XdQxEN9E6IGHOoI/MEHH4DaIMICpTAUwQEBAVR8EUIzmZmZoFG4JmD7wYRUpUkXGv3A5IBowBWrYtcYeOAhHDZs2DCwo/Daq1eviIgIahMEHSHkCXcExA0+OgQxoMhGBgPKhuhHVTxFCpb2GYPHFy6xHsVE7ewzBoEw+NXMtYhWpc9YeSBiCre+6rJmaRsgXwXCVA2Iv7KwaV6nAhqxVovgTdfabmD6AQ4AWEfEGsCzh+qaTj29WapF8Bf1C1XUWuDpfWdY25joahQRa/PpgNuLVFU8hKkaQhWIHUCQLj09vWPHjjodxVIt1vIesvqhUMGGqhtUyaGBG+kIS7VYjQN+uQtEHqDeamtrW+1yBC3euXMH6YgxtGhjY6NrTAdi4OCJV735QQ0brAJSyQJ+NTI6jx8/TklJ6datG6IVna4qeIp6GEXE2rwR0AyQkZHBrTTuGAoIpG/atKl+/fpIR1haRsMvMWaKy5oENOLBpTM8i4N+3Lp1y8XFRQ8hItZqkQ25HzgKRPWggfHChQuoOtAjlKOGpfHF5ORkdX9SjE44OTlBEVn13tQ0Aq7qs2fP9PZWWarF0NBQw6forrU0adKkWuZZ1y+Uo4alWnRzc9PseY/RlS+//FKncU+0YEgBjVirxQ4dOkB1DGH05aOPPjLanJIUZ86cGThwoCGpBlka00lNTc3OzsYpZTnEyJEjV69ebcjMsiy1ixEREcePH0cYA8jMzGRuXiAtwsPDra2tDZzimKVadHV19fHxQRgDsLe3Hz16tHE670CtxRBPkQLPTVmTCQkJgdbILl26ICYBAzxmzJjLly8jw2CpFqEBMD09vWXLlgjDenbs2GFqagoBdmQYLC2jo6OjDx06hDAGA+YqMjISMYmBoRw1LNUiNB60aNECYQwGYhErV65EjAGNjT179qRl0mDsL9Z84uLi7Ozs1AmM6GXcuHGLFi2iJfrGUrsI7jDTJUvtwcvLiyEhPnjwgMfj0RUGZqkWY2Nj9+3bhzA0ERgYqO5rQs3gTgt0eYoULNUiNO1zLsMimxk7dizIsVOnTm3bthUKhffu3UMGk5eX9++//2rlizMElvZf9FaBMHQwYMCAlJQUapwAhBuhVKVlxCC9RhGx1i7m5uZCsxLCGEyPHj3S0tK0BqzQMllibdFifHw8RFARxmCmTJmilU8QTONbJpqsIleuXOnQoQO948tYqkVbW1vNrL0YvYEm6WXLlnl6eqqHYkIBbbhdpKUBWguWatHDw2PatGkIQwfwVG/fvt3Pz4/KgACiNDAhB1TJRSIR7cO7WBrrLigogGZAA2cZqQ08iywqLpZqriEIpLylBELqG0stEyg4ODg29ilYxekzZvC1MnNo7Y9eH4K0TqU6/7nfLri7ubVq7YfkpTtXDkkSVnWE7k3fnXyBXVqcPHkylSYeXjMyMlxcXOAhhkcQvBOEKcuJDYlZ6RKCRBKxsvBVC4bS4pu3qldKUYiSKVIQcN/Lno0ooz3lS4VSLD2bQvU56hO++ZTy8EiC5MN2wqOxRb9Jjqhy2BXT8fX1PXz4sPot1RWUriTmNYmf1yQp5Gjg5/Wt7bmReCjhoSj0Uvr101k9hlWaU5Rd/iI0brq7u2uuAbvYvn17hNHg0MoEgSn50Qx3rggRqN/cdPj8+nFR+b/tTKtsH3ZpEWIE/fr100xA7ejoOGrUKIQpJeZOUXGh7H8B9RAH8R/rlvS80n7mrKtHg/I0TSOU2k2bNkWYUh7dyrWow9WMvVb2PD6fCPu94hm1WKdFS0vLoUOHUsm67e3tx4wZgzAaFBVJEKlb0jZWIZcr8nIrnieKjfHF4cOHU00FzZo1q64cRaxFKpZLxRzWolQml0krjgMZVI+WFKOQCy8zEsTFhRJRsTLWJJe9qdcTyngRoRUSeP1OHW8o3USQhEKuUMfGenmulbnLBAL+zoXPleEFBaE+A3UIQWhEo4jS0EJp7EIrJAZGluSRPD5hZsXz9LHo2K+2T4VerRCokkdJTy1ePpj+4gkIUE4KeBA15ZvyTSxIZYZeraioVvCyjILK7KAZFdMKlWkJq7Jza55e6wg+nwc6l5VIszKkr1Kybv+RaWrOa9qhTteP7BHGuJAk2IWKQ9o6a/HSgfS4hwVgZqwcrFyb6zz/DHYeXpkAAAsmSURBVBuQieVJUa/u38i5fzOnTS/bTv249CsguI24PCoEWsXlMjrK6D2L4+Bcnr4u5g4czqfNE5L12ygbAF4+z7t7LSs6ND/gm/qII0CIm9NaVMbryIp/QFXrLkmPi7fOeWrlYOnTw4PTQtTEoUGdZr09CR5vx7xnCGMUwI0iDNFiZqo4eE9Ks/e9XHw4WSi/Ha/2Ls5NHLbPx3I0BnI5oZBWrLp3azEhuvjEpsQWfTxr8JQrdu4WXq3duCFH8t1dY9gMCUaRp69dPL8vxbuDO6rpmNvx69a32bmQ7XIkFJyWotIuokrqLu/Q4t6lcVZOFkLLWjELlZO3jcCEf3yDkfLE6YcybMblugsEdHh62MVrJ19JSuQevrWoy5Z3F7dXyaLUODHCMAPEYSqbdPRtWnz4X46DV61rorCwMzu/PxlhmIEkCLKSUrZSLYacy4RQkIMXI7kvDCfywdX5X3csKMxGdOPVzllUKMvLZGmbrzI+Z3SHccU3X85fQM/wo7fEuivVYvTtPHMbQ0cuchShKf/K0VTESpTOoo7+4tngoDXrliN2QPCQznaxpFjm3Kga5ghhAxYOFi+TRaim8PhxNGINChnYxYo3VdwGGBNaCGbUzJqp0TDxL+5fubYvMSna0sK2aZOu/r0mm5oqE/iF3Dr5x/WfPg/Yefj4V+kZz12cvLt3GdW+zQDqqPOXt4bdu2giNG/t29exrgdiDBdvm+ykXFQjmD038N69u0g5uv7C7l1HGzfyefEifvOWtU9iY3g8vqdngwnjp7Ru1Y7aOSTk+qHDexJexFlb23h7N5k180snJ2etE94KDTlx4vCjxw/t7Oq2aOEXOHmmvb0ONustPkbFdjEuJp/kMxXHeZWZuPvgTImkZEbgvvGj16Wmx+786XOZTDmwkscXFBfnB1/YMHzw4u9X3vJt0TsoeHV2jnKExL+3T/97+9TQ/gtmTTlgb1vvj2v7EWPwBCRJEo/vFCDus3nTnqZNW/j797/2ZxgIMTs7a8bMiY6Oznt2H9u+9YCtjd2q1Yup/PJh4aHLViyAPYOOX1z+9dr09NTNP67VOtuT2EdfLZ7VunX7gz+d+mLmwmfPnqxbvwLphuYQkjJUrMWCLCncD8QMd+9d5vMEE0atc3LwdHZs8MlHS5JTH0fFXKe2ymSSD3pNru/eEr5yu1b9FQpFcuoTWH/zvyDf5u+DOs3N64Cl9G7QDjEJj0e8TClB7IOAiiihf+Xl5KmfhSYm8+ctrefi6ubmsWD+suLiol/PnYRNPx3Y2b1b74+HjQaj2Ly577TP5966dfNR2fI96kGkqanpp2MCwF527NBl4/c7R42agHRB2bGwkmphxYKTSuUEY7U1KKDd3ZpZWLxOxWJn62Jv5xaX8Cbzp4drc2rB3Ew5bW+xKB++/6usRCdHL/U+bvWYnnGDLCqQIPZBvB6ZrCfP4542auRDDeEALCws3N3qP3kSo9z0PNbHp7l6zyaNlRk+Hz0qM5Fbi5atRCLRV0tmg6aTkhNBteryvYpAxYWopMStxCNUIBljPZOKRQWJydEQkdFcmZefqV4u/9yLSgrlcpmJyZvMG0Ih03V8BUmwcQCGQmFQdoWszFeurmVadE3NzIqKiwoKCkpKSkxMTNXrqTwnRUWFmjtDKb92zY///PPnnr1bd+z8oW2bDuBugteIqgxUXBQ61V2Epjwyv5IjDMbKyt6rfqu+vQM1V1pYvC2QaWpiQZI8ieRN3bZEzOwUOnC/zSzY2PJpYBuguYWFqKRMiKC4qMjN1QNKXlgWid6MiipUqdDeTrteAkUz/E2cMDU8PPT0mV8WL5l95vQfakNrCBU/+nXsBXIpU1qs59QoJzetgWdr7wZtqT9LS1vHup5vOQQspa2NS/yLB+o1MY9DEJPI5XInzxoYXoWSNyYmSiJ57X7k5edBrdnLqyGIqUnjpg8f3lfvSS03aNhI8/DIyPDQ2/8iZeJgh759B0yfNi+/ID8tXYdYLDjiSKf4YiM/S7mUqTIawjRwp89d+kEsFmW8TDj/+7aN20anpj99+1F+Lfo8iL4GzS2w/NeNwwlJUYgxxAUQBFN4+xmUjIshoO6iqycPhTLo727EHahEDxw4rLCwYOOmb9PT0+Ljn69Zu8zUxLTf/wbDbkMGj7gZ8vfp07+AQCMiw3bs3NSmdftG3mVmTo56eG/FNwt/O38mJyc7OibqzNnjIEpnJ5eqfxmZTOn/VUjFptWrpblcIc9/VWJVl/4u3FARnj/j2LUbRzbvGp/xMt7Drfkng5e8sy7Sp8fEwsLs4IsbjwYtgSJ+0P9mHzu5jKHEVOlx2QJTlmaPVsgVunryA/sPhdrJgoXT163d2q5tx+XL1h45sm/k6AFQ84Bwz5bN+6jZWSCa8/JVxomTR7bt2AjV5HZtO302eYbWqYZ/8imocNv2DZt++E4oFPbu1feHTXtoKaDRW/KMHVqVIFPwGrTXQfI1hsf/JLrUNx001Rmxj0Or4qFJ9+PZnoibHFn9rHErqz5jKkg4VmlV0fc96+K8mtMOphMlIsmgQDYKsQbwlrpXpda1dW+b0CtZKY8y6/lUPIg4Jzd9w7bRFW4yM7EsLqm40cLZocGMwL2IPpZ++35lm6AtB5q5yq/39PCdPPaHyo56djvVxl7I1oS9nAfidZXFyt5W0nfwt7t1OasyLVpZ2s+ddqTCTVApEQpNK9xEkjT7YZV9B+XXkJQIBRX4u3ze23IjFeeKxq9l73QeBMHtMQaqDKK6j9Vv09vm/s3cuLA0r3YVFFhgcuxsqz/zGr3f4cmNRLdG5nwW5/FStgBy2WYrq176jXeZsKx+cb4oJ8UYc7NXO0lRL0meYvDnrE5tqEAKBacHvFTOux+xaWsbJkVnoJpOysPsgpdFk1d5IXajkHN87BUoTu8xqbDL5+sbRv0Rl51cY61j4oPMwpyCqesbIAzDQBmNdOqnowWPh2Zs8k6JSX9+h6U97w3hSUhSUXbBZ6s9EcYIKNCbDIZl0cENnr7RG8mlMdcS0p7QP+KpWoiPzAB7b2vLn7KGUxaxhvqLukVYAlZ43r6SE/FXVlZSnrmVSV1vO0tb7uWOzk4uzErIFRWJhWbkkCnurk24lqqK4HBUB/xFHl35Fzv428Bf+NXc+yE58eHJEO2CEAOPz1O22ZOobJddhfqyKd6sUP5fmqtToZEE9E16T/UaNUTp/DZl1yBVwtoyx74+Z9lMoVA7hjiC0lORySViKckj69gL+4x0rd/cFGGMC9wXmZzWHMlt+1jDHyzE3i2MvZdfmCMtLpTJZWW7jytzGyuD7G+GUaozHFOqJVRdQ0kFoToKnpjX0ycS2sWQcn9E+b2l4iXhswjVBE7KzMrwV3qs4vV8TBrfhC8gCB5hZsG3dRI0aWvl6o0lWG28ZUytoa0gjdpYwB/CYAyGpT2jMJUhMCEVHJ7GAAlNSL6JvvkXMazC3FIgkyLuAq6UvVPF9V2sRY7R0d++MI+rYkx5KkYyhW/3OhVuxVrkGC7eQlsH4dkfExEH+ed0akM/q8q2snQuc8zbubg/PTVB1LyzbfMudRDrERehe9czn0Tm9fzYwaedZWW7YS1ylUsHMhJjC6ViuUxW+R1UVJa8pqINylCZ9kqoJ5XroqZ1rPaptN6Tykk0CFMznm83m/b+NqhysBY5T3Fu2XF1b+K0VJYJjbdI5ZTJSwO9ZfYkqf5ob/ZRpisgCXnZ2K9yPgw5oXksDynH9VFvX5+8NN6rWinjIcuq5djGWsSwBRxfxLAFrEUMW8BaxLAFrEUMW8BaxLAFrEUMW/g/AAAA///6Ql0yAAAABklEQVQDAGv7kUD9Un2WAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization shows the flow: Agent → Decision → Tools → Agent → Decision → End\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Complete ReAct Agent\n",
    "\n",
    "### Final Execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the weather like in Zurich, and what should I wear based on the temperature?\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'model_provider'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m             message.pretty_print()\n\u001b[32m     10\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mWhat\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms the weather like in Zurich, and what should I wear based on the temperature?\u001b[39m\u001b[33m\"\u001b[39m)]}\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mprint_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mprint_stream\u001b[39m\u001b[34m(stream)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_stream\u001b[39m(stream):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Helper function for formatting the stream nicely.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcall_model\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(state: AgentState):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Invoke the model with the current conversation state.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     response = \u001b[43mmodel_react\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscratch_pad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3151\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3149\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3150\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3151\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3152\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3153\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5557\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5550\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5552\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5555\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5556\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5558\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5559\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5560\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1386\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1384\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1385\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1389\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1390\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1391\u001b[39m ):\n\u001b[32m   1392\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1381\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1374\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1375\u001b[39m             response,\n\u001b[32m   1376\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1377\u001b[39m             metadata=generation_info,\n\u001b[32m   1378\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1379\u001b[39m         )\n\u001b[32m   1380\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1382\u001b[39m         response = raw_response.parse()\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ws/dev/git/ai/Agentic-AI-with-LangChain-and-LangGraph/venv/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Completions.create() got an unexpected keyword argument 'model_provider'",
      "During task with name 'agent' and id '494fb27d-a99d-f913-12bc-39c35e594118'"
     ]
    }
   ],
   "source": [
    "def print_stream(stream):\n",
    "    \"\"\"Helper function for formatting the stream nicely.\"\"\"\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"What's the weather like in Zurich, and what should I wear based on the temperature?\")]}\n",
    "\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What You'll See:**\n",
    "1. **Initial Reasoning**: Agent analyzes the query.\n",
    "2. **Tool Call 1**: Searches for Zurich weather.\n",
    "3. **Tool Result Processing**: Agent examines weather data.\n",
    "4. **Tool Call 2**: Gets clothing recommendations.\n",
    "5. **Final Synthesis**: Agent combines all information into a helpful response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Complete ReAct Cycle\n",
    "\n",
    "The final execution demonstrates the full ReAct pattern:\n",
    "\n",
    "1. **Reasoning**: \"I need current weather data for Zurich\".\n",
    "2. **Acting**: Calls search_tool(\"Zurich weather today\").\n",
    "3. **Observing**: Processes search results, extracts temperature.\n",
    "4. **Reasoning**: \"Now I need clothing recommendations for this temperature\".\n",
    "5. **Acting**: Calls recommend_clothing(\"temperature from search\").\n",
    "6. **Observing**: Gets clothing suggestions.\n",
    "7. **Reasoning**: \"I can now provide a complete answer\".\n",
    "8. **Final Response**: Synthesizes weather info and clothing recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Makes ReAct Powerful\n",
    "\n",
    "1. **Transparency**: You can see the agent's reasoning process.\n",
    "2. **Adaptability**: The agent can handle unexpected results and change course.\n",
    "3. **Extensibility**: It's easy to add new tools and capabilities.\n",
    "4. **Reliability**: The structured approach reduces hallucination and improves accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices\n",
    "\n",
    "1. **Tool Design**: Make tools focused and reliable.\n",
    "2. **Error Handling**: Plan for tool failures and unexpected results.\n",
    "3. **Context Management**: Keep state manageable and relevant.\n",
    "4. **User Experience**: Provide clear feedback about what the agent is doing.\n",
    "\n",
    "The ReAct framework represents a significant step toward more capable and trustworthy AI agents that can reason through complex problems and take meaningful actions in the real world.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Now it's time to put your ReAct knowledge into practice! These exercises will help you build your own tools and extend the agent's capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Build a Calculator Tool\n",
    "\n",
    "**Objective:** Create a mathematical calculator tool that can handle complex calculations.\n",
    "\n",
    "Your task is to create a calculator tool that can perform mathematical operations. This tool should be able to handle expressions like \"2 + 3 * 4\", \"sqrt(16)\", and \"sin(π/2)\".\n",
    "\n",
    "### Instructions:\n",
    "1. Create a tool called `calculator_tool` using the `@tool` decorator.\n",
    "2. The tool should accept a mathematical expression as a string.\n",
    "3. Use Python's `eval()` function carefully (or better yet, use the `ast` module for safety).\n",
    "4. Test your tool with various mathematical expressions.\n",
    "5. Add your tool to the tools list and test it with the ReAct agent.\n",
    "\n",
    "### Starter Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import ast\n",
    "import operator\n",
    "\n",
    "@tool\n",
    "def calculator_tool(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Safely evaluate mathematical expressions.\n",
    "    \n",
    "    :param expression: A mathematical expression as a string (e.g., \"2 + 3 * 4\")\n",
    "    :return: The result of the calculation\n",
    "    \"\"\"\n",
    "    # TODO: Implement safe mathematical evaluation\n",
    "    # Hint: You can use ast.literal_eval for simple expressions\n",
    "    # or create a safe evaluator for more complex math\n",
    "    pass\n",
    "\n",
    "# TODO: Add calculator_tool to your tools list\n",
    "# TODO: Test with the agent: \"What's 15% of 250 plus the square root of 144?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Create a News Summary Tool\n",
    "\n",
    "**Objective:** Build a tool that can fetch and summarize recent news articles.\n",
    "\n",
    "Create a news summarization tool that works with the existing search functionality. This tool should take search results and create concise summaries of news articles.\n",
    "\n",
    "### Instructions:\n",
    "1. Create a `news_summarizer_tool` that takes news content and creates summaries.\n",
    "2. The tool should extract key information: headline, date, main points.\n",
    "3. Format the output in a readable way.\n",
    "4. Test it by asking the agent to \"search for recent AI news and summarize the top 3 articles\".\n",
    "\n",
    "### Starter Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def news_summarizer_tool(news_content: str) -> str:\n",
    "    \"\"\"\n",
    "    Summarize news articles from search results.\n",
    "    \n",
    "    :param news_content: Raw news content or search results\n",
    "    :return: A formatted summary of the news\n",
    "    \"\"\"\n",
    "    # TODO: Parse the news content\n",
    "    # TODO: Extract key information (headlines, dates, main points)\n",
    "    # TODO: Format into a readable summary\n",
    "    # Hint: You might want to split by articles and process each one\n",
    "    pass\n",
    "\n",
    "# TODO: Add to tools list and test with:\n",
    "# \"Find recent news about artificial intelligence and give me a summary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Your Solutions\n",
    "\n",
    "For each exercise, test your implementation with these commands:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Exercise 1 Test\u001b[39;00m\n\u001b[32m      2\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mCalculate 15\u001b[39m\u001b[38;5;132;01m% o\u001b[39;00m\u001b[33mf 250 plus the square root of 144\u001b[39m\u001b[33m\"\u001b[39m)]}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mprint_stream\u001b[49m(graph.stream(inputs, stream_mode=\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'print_stream' is not defined"
     ]
    }
   ],
   "source": [
    "# Exercise 1 Test\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Calculate 15% of 250 plus the square root of 144\")]}\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Exercise 2 Test  \u001b[39;00m\n\u001b[32m      2\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mFind recent AI news and summarize the top 3 articles\u001b[39m\u001b[33m\"\u001b[39m)]}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mprint_stream\u001b[49m(graph.stream(inputs, stream_mode=\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'print_stream' is not defined"
     ]
    }
   ],
   "source": [
    "# Exercise 2 Test  \n",
    "inputs = {\"messages\": [HumanMessage(content=\"Find recent AI news and summarize the top 3 articles\")]}\n",
    "print_stream(graph.stream(inputs, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Joseph Santarcangelo](https://author.skills.network/instructors/joseph_santarcangelo): Joseph has a Ph.D. in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n",
    "\n",
    "[Tenzin Migmar](https://author.skills.network/instructors/tenzin_migmar): Hi, I'm Tenzin. I'm a data scientist intern at IBM interested in applying machine learning to solve difficult problems. Prior to joining IBM, I worked as a research assistant on projects exploring perspectivism and personalization within large language models. In my free time, I enjoy recreational programming and learning to cook new recipes.\n",
    "\n",
    "[Faranak Heidari](https://www.linkedin.com/in/faranakhdr/) is a data scientist and AI developer in IBM. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--#### Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2024-02-23|0.2|Elio Di Nino|Update library documentation|\n",
    "|2020-07-17|0.1|Sam|Create lab template|\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "prev_pub_hash": "8c934cd1f83b596adfcbc5587f1033178f6fdba432838b18df7d9d0e24b2f6c9"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
